{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87108c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4274c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------------------------------------------------------------------------------------#\n",
      "setting seed: 517\n",
      "train folds: [1, 99]\n",
      "valid folds: [0]\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "# images in \"original train\": 60014\n",
      "# images in \"original train\" after multiplier: 180042\n",
      "full-fit: using all data for training...\n",
      "# extracted train ids: 554\n",
      "# images in \"original train\" after extracted (multiplier to extracted): 188352\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 24576 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done 60578 out of 60578 | elapsed:    1.9s finished\n",
      "labels:\n",
      "               id     source  ...    chart_type    data_type\n",
      "0  d0776256aaa9_x  extracted  ...  vertical_bar  categorical\n",
      "1  d21849cdda48_x  extracted  ...  vertical_bar  categorical\n",
      "2  d21849cdda48_y  extracted  ...  vertical_bar    numerical\n",
      "\n",
      "[3 rows x 5 columns]\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "# of graphs in train: 188352\n",
      "# of graphs in valid: 564\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "adding  data from ./datasets/processed/synthetic/images\n",
      "# Synthetic before filter: 662437\n",
      "# Synthetic after filter: 661927\n",
      "# SYN ids after exclusion: 661921\n",
      "# of graphs in train: 850273\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "adding  data from ./datasets/processed/mga_pl/images\n",
      "# PL ids before exclusion: 610\n",
      "# PL ids after exclusion: 610\n",
      "# PL before multiplier: 610\n",
      "# PL after multiplier: 4880\n",
      "# of graphs in train: 4880\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "using augmentations...\n",
      "/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/albumentations/augmentations/blur/transforms.py:184: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  warnings.warn(\n",
      "/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1692: UserWarning: Using default interpolation INTER_NEAREST, which is sub-optimal.Please specify interpolation mode for downscale and upscale explicitly.For additional information see this PR https://github.com/albumentations-team/albumentations/pull/584\n",
      "  warnings.warn(\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "loading processor from google/matcha-base\n",
      "adding new tokens...\n",
      "loading processor from google/matcha-base\n",
      "adding new tokens...\n",
      "# of tokens in tokenizer: 50359\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "config for the current run\n",
      "{\n",
      "    \"debug\": false,\n",
      "    \"use_random_seed\": true,\n",
      "    \"seed\": 517,\n",
      "    \"fold\": 0,\n",
      "    \"train_folds\": [\n",
      "        1,\n",
      "        99\n",
      "    ],\n",
      "    \"valid_folds\": [\n",
      "        0\n",
      "    ],\n",
      "    \"use_wandb\": false,\n",
      "    \"all_data\": false,\n",
      "    \"add_syn\": true,\n",
      "    \"add_pl\": true,\n",
      "    \"add_icdar\": false,\n",
      "    \"pl_multiplier\": 8,\n",
      "    \"extracted_multiplier\": 16,\n",
      "    \"original_multiplier\": 3,\n",
      "    \"use_augmentations\": true,\n",
      "    \"tags\": [\n",
      "        \"final\"\n",
      "    ],\n",
      "    \"model\": {\n",
      "        \"backbone_path\": \"google/matcha-base\",\n",
      "        \"max_length\": 1024,\n",
      "        \"max_patches\": 2048,\n",
      "        \"patch_size\": 16,\n",
      "        \"len_tokenizer\": 50359,\n",
      "        \"pad_token_id\": 0,\n",
      "        \"decoder_start_token_id\": 50350,\n",
      "        \"bos_token_id\": 50350,\n",
      "        \"max_length_generation\": 16\n",
      "    },\n",
      "    \"awp\": {\n",
      "        \"use_awp\": false,\n",
      "        \"awp_trigger\": 0.0,\n",
      "        \"awp_trigger_epoch\": 1,\n",
      "        \"adv_lr\": 8e-05,\n",
      "        \"adv_eps\": 0.001\n",
      "    },\n",
      "    \"train_params\": {\n",
      "        \"train_bs\": 1,\n",
      "        \"valid_bs\": 1,\n",
      "        \"num_epochs\": 4,\n",
      "        \"grad_accumulation\": 16,\n",
      "        \"warmup_pct\": 0.05,\n",
      "        \"save_trigger\": -1.0,\n",
      "        \"use_fp16\": true,\n",
      "        \"eval_frequency\": 16000,\n",
      "        \"patience\": 100,\n",
      "        \"use_ema\": true,\n",
      "        \"decay_rate\": 0.9925\n",
      "    },\n",
      "    \"optimizer\": {\n",
      "        \"lr\": 5e-05,\n",
      "        \"weight_decay\": 1e-05,\n",
      "        \"grad_clip_value\": 1.0\n",
      "    },\n",
      "    \"outputs\": {\n",
      "        \"model_dir\": \"./models/r_final\"\n",
      "    },\n",
      "    \"fold_metadata\": {\n",
      "        \"n_folds\": 2,\n",
      "        \"fold_dir\": \"./datasets/processed/fold_split\",\n",
      "        \"fold_path\": \"cv_map_2_folds.parquet\"\n",
      "    },\n",
      "    \"competition_dataset\": {\n",
      "        \"data_dir\": \"./input\",\n",
      "        \"syn_dir\": \"./datasets/processed/synthetic\",\n",
      "        \"pl_dir\": \"./datasets/processed/mga_pl\"\n",
      "    },\n",
      "    \"wandb\": {\n",
      "        \"project\": \"mga-dev-a1\",\n",
      "        \"run_name\": \"rb-exp100-r-final\"\n",
      "    }\n",
      "}\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "creating the MGA model...\n",
      "initializing the MGA model...\n",
      "resizing model embeddings...\n",
      "tokenizer length = 50359\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "creating the optimizer...\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "creating the scheduler...\n",
      "# training updates per epoch: 53447\n",
      "# training steps: 213788\n",
      "# warmup steps: 10689\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "accelerator setup...\n",
      "model preparation done...\n",
      "current GPU utilization...\n",
      "GPU memory occupied: 2319 MB.\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "EMA will be used during evaluation with decay 0.9925...\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "  0%|                                                 | 0/53447 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Error executing job with overrides: ['fold=0', 'use_wandb=false', 'debug=false']\n",
      "Traceback (most recent call last):\n",
      "  File \"./code/train_r_final.py\", line 694, in <module>\n",
      "    run_training()\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/main.py\", line 94, in decorated_main\n",
      "    _run_hydra(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
      "    _run_app(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
      "    run_and_report(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
      "    raise ex\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
      "    lambda: hydra.run(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/hydra.py\", line 132, in run\n",
      "    _ = ret.return_value\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/core/utils.py\", line 186, in run_job\n",
      "    ret.return_value = task_function(task_cfg)\n",
      "  File \"./code/train_r_final.py\", line 531, in run_training\n",
      "    loss, loss_dict = model(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/accelerate/utils/operations.py\", line 581, in forward\n",
      "    return model_forward(*args, **kwargs)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/accelerate/utils/operations.py\", line 569, in __call__\n",
      "    return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/amp/autocast_mode.py\", line 14, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/media/na/e0adac50-20ce-4eb4-9c9d-98faf82ddd46/code/r_final/mga_model.py\", line 58, in forward\n",
      "    outputs = self.backbone(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/transformers/models/pix2struct/modeling_pix2struct.py\", line 1729, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/transformers/models/pix2struct/modeling_pix2struct.py\", line 639, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/transformers/models/pix2struct/modeling_pix2struct.py\", line 360, in forward\n",
      "    layer_outputs = layer_module(hidden_states, attention_mask, layer_head_mask, output_attentions)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/transformers/models/pix2struct/modeling_pix2struct.py\", line 299, in forward\n",
      "    self_attention_outputs = self.attention(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/transformers/models/pix2struct/modeling_pix2struct.py\", line 224, in forward\n",
      "    attn_weights = nn.functional.softmax(scores, dim=-1, dtype=torch.float32).type_as(scores)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/nn/functional.py\", line 1845, in softmax\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ret = input.softmax(dim, dtype=dtype)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "  0%|                                                 | 0/53447 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# domain adaptation phase.\n",
    "# training over a large number of synthetic plots to adapt the \"google/matcha-base\" backbone for the current task.\n",
    "!HYDRA_FULL_ERROR=1 python ./code/train_r_final.py \\\n",
    "--config-name conf_r_final \\\n",
    "fold=0 \\\n",
    "use_wandb=false \\\n",
    "debug=false\n",
    "# valid_folds = [fold]\n",
    "\n",
    "# mga_pl dataset means:\n",
    "# pseudo-labeling images from https://commons.wikimedia.org/w/index.php?search=line+plots&title=Special:MediaSearch&go=Go&type=image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08624c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8e184ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------------------------------------------------------------------------------------#\n",
      "setting seed: 522\n",
      "train folds: [1, 99]\n",
      "valid folds: [0]\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  42 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 24576 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done 60578 out of 60578 | elapsed:    2.1s finished\n",
      "labels:\n",
      "               id     source  ...  data_type   original_id\n",
      "0  7dbdb91fa4a7_x  generated  ...  numerical  7dbdb91fa4a7\n",
      "1  7dbdb91fa4a7_y  generated  ...  numerical  7dbdb91fa4a7\n",
      "2  bebbd7264548_x  generated  ...  numerical  bebbd7264548\n",
      "3  bebbd7264548_y  generated  ...  numerical  bebbd7264548\n",
      "4  cdfca7cc9abf_x  generated  ...  numerical  cdfca7cc9abf\n",
      "\n",
      "[5 rows x 6 columns]\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "# images in original train: 60014\n",
      "# images in original train (only scatter): 11169\n",
      "# images in extracted (only scatter): 91\n",
      "# images in original train after multiplier: 22338\n",
      "# extracted train ids: 91\n",
      "# images in original train after extracted multiplier: 23703\n",
      "# of graphs in train: 23703\n",
      "# of graphs in valid: 74\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "adding  data from ./datasets/processed/synthetic/images\n",
      "# Synthetic before filter: 208374\n",
      "# Synthetic after filter: 208214\n",
      "# SYN ids after exclusion: 208209\n",
      "sampling 30k syn ids\n",
      "# of graphs in train: 53703\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "adding  data from ./datasets/processed/mga_pl/images\n",
      "# PL ids before exclusion: 610\n",
      "# PL ids after exclusion: 610\n",
      "# PL before multiplier: 610\n",
      "# PL after multiplier: 9760\n",
      "# of graphs in train: 9760\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "adding  data from ./datasets/processed/mga_icdar/images\n",
      "# ICDAR ids before exclusion: 1341\n",
      "# ICDAR ids after exclusion: 152\n",
      "# ICDAR before multiplier: 152\n",
      "# ICDAR after multiplier: 2432\n",
      "# of graphs in train: 65895\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "using augmentations...\n",
      "/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/albumentations/augmentations/blur/transforms.py:184: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  warnings.warn(\n",
      "/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1692: UserWarning: Using default interpolation INTER_NEAREST, which is sub-optimal.Please specify interpolation mode for downscale and upscale explicitly.For additional information see this PR https://github.com/albumentations-team/albumentations/pull/584\n",
      "  warnings.warn(\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "loading processor from google/matcha-base\n",
      "adding new tokens...\n",
      "loading processor from google/matcha-base\n",
      "adding new tokens...\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "config for the current run\n",
      "{\n",
      "    \"debug\": false,\n",
      "    \"use_random_seed\": true,\n",
      "    \"seed\": 522,\n",
      "    \"fold\": 0,\n",
      "    \"train_folds\": [\n",
      "        1,\n",
      "        99\n",
      "    ],\n",
      "    \"valid_folds\": [\n",
      "        0\n",
      "    ],\n",
      "    \"use_wandb\": false,\n",
      "    \"all_data\": false,\n",
      "    \"add_syn\": true,\n",
      "    \"add_pl\": true,\n",
      "    \"add_icdar\": true,\n",
      "    \"pl_multiplier\": 16,\n",
      "    \"extracted_multiplier\": 16,\n",
      "    \"icdar_multiplier\": 16,\n",
      "    \"original_multiplier\": 2,\n",
      "    \"use_augmentations\": true,\n",
      "    \"tags\": [\n",
      "        \"final\"\n",
      "    ],\n",
      "    \"model\": {\n",
      "        \"backbone_path\": \"google/matcha-base\",\n",
      "        \"max_length\": 1024,\n",
      "        \"max_patches\": 3072,\n",
      "        \"patch_size\": 16,\n",
      "        \"len_tokenizer\": 50359,\n",
      "        \"pad_token_id\": 0,\n",
      "        \"decoder_start_token_id\": 50350,\n",
      "        \"bos_token_id\": 50350,\n",
      "        \"max_length_generation\": 16,\n",
      "        \"ckpt_path\": \"./models/r_final/mga_model_fold_0_best.pth.tar\"\n",
      "    },\n",
      "    \"awp\": {\n",
      "        \"use_awp\": true,\n",
      "        \"awp_trigger\": -100,\n",
      "        \"awp_trigger_epoch\": 1,\n",
      "        \"adv_lr\": 5e-05,\n",
      "        \"adv_eps\": 0.001\n",
      "    },\n",
      "    \"train_params\": {\n",
      "        \"train_bs\": 1,\n",
      "        \"valid_bs\": 1,\n",
      "        \"num_epochs\": 4,\n",
      "        \"grad_accumulation\": 4,\n",
      "        \"warmup_pct\": 0.05,\n",
      "        \"save_trigger\": -1.0,\n",
      "        \"use_fp16\": true,\n",
      "        \"eval_frequency\": 1024,\n",
      "        \"patience\": 100,\n",
      "        \"use_ema\": true,\n",
      "        \"decay_rate\": 0.9925\n",
      "    },\n",
      "    \"optimizer\": {\n",
      "        \"lr\": 4e-05,\n",
      "        \"weight_decay\": 1e-05,\n",
      "        \"grad_clip_value\": 1.0\n",
      "    },\n",
      "    \"outputs\": {\n",
      "        \"model_dir\": \"./models/r_scatter_matcha\"\n",
      "    },\n",
      "    \"fold_metadata\": {\n",
      "        \"n_folds\": 2,\n",
      "        \"fold_dir\": \"./datasets/processed/fold_split\",\n",
      "        \"fold_path\": \"cv_map_2_folds.parquet\"\n",
      "    },\n",
      "    \"competition_dataset\": {\n",
      "        \"data_dir\": \"./input\",\n",
      "        \"syn_dir\": \"./datasets/processed/synthetic\",\n",
      "        \"pl_dir\": \"./datasets/processed/mga_pl\",\n",
      "        \"icdar_dir\": \"./datasets/processed/mga_icdar\"\n",
      "    },\n",
      "    \"wandb\": {\n",
      "        \"project\": \"mga-dev-a1\",\n",
      "        \"run_name\": \"rb-exp101-r-scatter\"\n",
      "    }\n",
      "}\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "creating the MGA model...\n",
      "initializing the MGA model...\n",
      "resizing model embeddings...\n",
      "tokenizer length = 50359\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "loading model from previously trained checkpoint...\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "creating the optimizer...\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "creating the scheduler...\n",
      "# training updates per epoch: 16473\n",
      "# training steps: 65892\n",
      "# warmup steps: 3294\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "accelerator setup...\n",
      "model preparation done...\n",
      "current GPU utilization...\n",
      "GPU memory occupied: 2319 MB.\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "EMA will be used during evaluation with decay 0.9925...\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "  0%|                                                 | 0/16473 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Error executing job with overrides: ['fold=0', 'use_wandb=false', 'debug=false']\n",
      "Traceback (most recent call last):\n",
      "  File \"./code/train_r_scatter.py\", line 739, in <module>\n",
      "    run_training()\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/main.py\", line 94, in decorated_main\n",
      "    _run_hydra(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
      "    _run_app(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
      "    run_and_report(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
      "    raise ex\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
      "    lambda: hydra.run(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/hydra.py\", line 132, in run\n",
      "    _ = ret.return_value\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/core/utils.py\", line 186, in run_job\n",
      "    ret.return_value = task_function(task_cfg)\n",
      "  File \"./code/train_r_scatter.py\", line 582, in run_training\n",
      "    optimizer.step()\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/accelerate/optimizer.py\", line 142, in step\n",
      "    self.optimizer.step(closure)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 69, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/optim/adamw.py\", line 171, in step\n",
      "    adamw(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/optim/adamw.py\", line 321, in adamw\n",
      "    func(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/optim/adamw.py\", line 564, in _multi_tensor_adamw\n",
      "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                 | 0/16473 [00:20<?, ?it/s]\r\n"
     ]
    }
   ],
   "source": [
    "# train \"google/matcha-base\" just for scatter plots.\n",
    "# the checkpoint from the domain adaptation phase is used as the starting point for the specialization phase.\n",
    "!HYDRA_FULL_ERROR=1 python ./code/train_r_scatter.py \\\n",
    "--config-name conf_r_scatter \\\n",
    "fold=0 \\\n",
    "use_wandb=false \\\n",
    "debug=false\n",
    "\n",
    "# mga_pl dataset means:\n",
    "# pseudo-labeling images from https://commons.wikimedia.org/w/index.php?search=line+plots&title=Special:MediaSearch&go=Go&type=image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f58db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2d4558e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------------------------------------------------------------------------------------#\n",
      "setting seed: 555\n",
      "train folds: [1, 99]\n",
      "valid folds: [0]\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 24576 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done 60578 out of 60578 | elapsed:    2.0s finished\n",
      "labels:\n",
      "               id     source  ...    data_type   original_id\n",
      "0  8941f843bb04_x  generated  ...  categorical  8941f843bb04\n",
      "1  8941f843bb04_y  generated  ...    numerical  8941f843bb04\n",
      "2  956c946a123d_x  generated  ...  categorical  956c946a123d\n",
      "3  956c946a123d_y  generated  ...    numerical  956c946a123d\n",
      "4  5fe5636e61d3_x  generated  ...  categorical  5fe5636e61d3\n",
      "\n",
      "[5 rows x 6 columns]\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "# images in original train: 60014\n",
      "# images in original train (non scatter): 48845\n",
      "# images in extracted (non scatter): 463\n",
      "# images in original train after multiplier: 48845\n",
      "# extracted train ids: 463\n",
      "# images in original train after extracted multiplier: 52086\n",
      "# of graphs in train: 52086\n",
      "# of graphs in valid: 490\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "adding  data from ./datasets/processed/synthetic/images\n",
      "# Synthetic before filter: 454063\n",
      "# Synthetic after filter: 453713\n",
      "# SYN ids after exclusion: 453712\n",
      "sampling 10k syn ids\n",
      "# of graphs in train: 62086\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "adding  data from ./datasets/processed/mga_pl/images\n",
      "# PL ids before exclusion: 610\n",
      "# PL ids after exclusion: 574\n",
      "# PL before multiplier: 574\n",
      "# PL after multiplier: 4592\n",
      "# of graphs in train: 4592\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "adding  data from ./datasets/processed/mga_icdar/images\n",
      "# ICDAR ids before exclusion: 1341\n",
      "# ICDAR ids after exclusion: 1189\n",
      "# ICDAR before multiplier: 1189\n",
      "# ICDAR after multiplier: 9512\n",
      "# of graphs in train: 76190\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "using augmentations...\n",
      "/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/albumentations/augmentations/blur/transforms.py:184: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  warnings.warn(\n",
      "/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1692: UserWarning: Using default interpolation INTER_NEAREST, which is sub-optimal.Please specify interpolation mode for downscale and upscale explicitly.For additional information see this PR https://github.com/albumentations-team/albumentations/pull/584\n",
      "  warnings.warn(\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "loading processor from google/matcha-base\n",
      "adding new tokens...\n",
      "loading processor from google/matcha-base\n",
      "adding new tokens...\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "config for the current run\n",
      "{\n",
      "    \"debug\": false,\n",
      "    \"use_random_seed\": true,\n",
      "    \"seed\": 555,\n",
      "    \"fold\": 0,\n",
      "    \"train_folds\": [\n",
      "        1,\n",
      "        99\n",
      "    ],\n",
      "    \"valid_folds\": [\n",
      "        0\n",
      "    ],\n",
      "    \"use_wandb\": false,\n",
      "    \"all_data\": false,\n",
      "    \"add_syn\": true,\n",
      "    \"add_pl\": true,\n",
      "    \"add_icdar\": true,\n",
      "    \"pl_multiplier\": 8,\n",
      "    \"extracted_multiplier\": 8,\n",
      "    \"icdar_multiplier\": 8,\n",
      "    \"original_multiplier\": 1,\n",
      "    \"use_augmentations\": true,\n",
      "    \"tags\": [\n",
      "        \"final\"\n",
      "    ],\n",
      "    \"model\": {\n",
      "        \"backbone_path\": \"google/matcha-base\",\n",
      "        \"max_length\": 512,\n",
      "        \"max_patches\": 4096,\n",
      "        \"patch_size\": 16,\n",
      "        \"len_tokenizer\": 50359,\n",
      "        \"pad_token_id\": 0,\n",
      "        \"decoder_start_token_id\": 50350,\n",
      "        \"bos_token_id\": 50350,\n",
      "        \"max_length_generation\": 8,\n",
      "        \"ckpt_path\": \"./models/r_final/mga_model_fold_0_best.pth.tar\"\n",
      "    },\n",
      "    \"awp\": {\n",
      "        \"use_awp\": false,\n",
      "        \"awp_trigger\": -100,\n",
      "        \"awp_trigger_epoch\": 1,\n",
      "        \"adv_lr\": 5e-05,\n",
      "        \"adv_eps\": 0.001\n",
      "    },\n",
      "    \"train_params\": {\n",
      "        \"train_bs\": 1,\n",
      "        \"valid_bs\": 1,\n",
      "        \"num_epochs\": 4,\n",
      "        \"grad_accumulation\": 2,\n",
      "        \"warmup_pct\": 0.05,\n",
      "        \"save_trigger\": -1.0,\n",
      "        \"use_fp16\": true,\n",
      "        \"eval_frequency\": 512,\n",
      "        \"patience\": 100,\n",
      "        \"use_ema\": true,\n",
      "        \"decay_rate\": 0.9925\n",
      "    },\n",
      "    \"optimizer\": {\n",
      "        \"lr\": 1e-05,\n",
      "        \"weight_decay\": 1e-05,\n",
      "        \"grad_clip_value\": 1.0\n",
      "    },\n",
      "    \"outputs\": {\n",
      "        \"model_dir\": \"./models/r_rest\"\n",
      "    },\n",
      "    \"fold_metadata\": {\n",
      "        \"n_folds\": 2,\n",
      "        \"fold_dir\": \"./datasets/processed/fold_split\",\n",
      "        \"fold_path\": \"cv_map_2_folds.parquet\"\n",
      "    },\n",
      "    \"competition_dataset\": {\n",
      "        \"data_dir\": \"./input\",\n",
      "        \"syn_dir\": \"./datasets/processed/synthetic\",\n",
      "        \"pl_dir\": \"./datasets/processed/mga_pl\",\n",
      "        \"icdar_dir\": \"./datasets/processed/mga_icdar\"\n",
      "    },\n",
      "    \"wandb\": {\n",
      "        \"project\": \"mga-dev-a1\",\n",
      "        \"run_name\": \"rb-exp101-r-rest\"\n",
      "    }\n",
      "}\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "creating the MGA model...\n",
      "initializing the MGA model...\n",
      "resizing model embeddings...\n",
      "tokenizer length = 50359\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "loading model from previously trained checkpoint...\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "creating the optimizer...\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "creating the scheduler...\n",
      "# training updates per epoch: 38095\n",
      "# training steps: 152380\n",
      "# warmup steps: 7619\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "accelerator setup...\n",
      "model preparation done...\n",
      "current GPU utilization...\n",
      "GPU memory occupied: 2314 MB.\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "EMA will be used during evaluation with decay 0.9925...\n",
      "#----------------------------------------------------------------------------------------------------#\n",
      "  0%|                                                 | 0/38095 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Error executing job with overrides: ['fold=0', 'use_wandb=false', 'debug=false']\n",
      "Traceback (most recent call last):\n",
      "  File \"./code/train_r_rest.py\", line 735, in <module>\n",
      "    run_training()\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/main.py\", line 94, in decorated_main\n",
      "    _run_hydra(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
      "    _run_app(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
      "    run_and_report(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
      "    raise ex\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
      "    lambda: hydra.run(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/_internal/hydra.py\", line 132, in run\n",
      "    _ = ret.return_value\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/hydra/core/utils.py\", line 186, in run_job\n",
      "    ret.return_value = task_function(task_cfg)\n",
      "  File \"./code/train_r_rest.py\", line 572, in run_training\n",
      "    accelerator.backward(loss)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/accelerate/accelerator.py\", line 1853, in backward\n",
      "    loss.backward(**kwargs)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/autograd/function.py\", line 274, in apply\n",
      "    return user_fn(self, *args)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/utils/checkpoint.py\", line 141, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/transformers/models/pix2struct/modeling_pix2struct.py\", line 349, in custom_forward\n",
      "    return module(*inputs, output_attentions)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/transformers/models/pix2struct/modeling_pix2struct.py\", line 299, in forward\n",
      "    self_attention_outputs = self.attention(\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/transformers/models/pix2struct/modeling_pix2struct.py\", line 224, in forward\n",
      "    attn_weights = nn.functional.softmax(scores, dim=-1, dtype=torch.float32).type_as(scores)\n",
      "  File \"/home/na/miniconda3/envs/base_4/lib/python3.8/site-packages/torch/nn/functional.py\", line 1845, in softmax\n",
      "    ret = input.softmax(dim, dtype=dtype)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                 | 0/38095 [00:03<?, ?it/s]\r\n"
     ]
    }
   ],
   "source": [
    "# train \"google/matcha-base\" just for scatter plots.\n",
    "# the checkpoint from the domain adaptation phase is used as the starting point for the specialization phase.\n",
    "!HYDRA_FULL_ERROR=1 python ./code/train_r_rest.py \\\n",
    "--config-name conf_r_rest \\\n",
    "fold=0 \\\n",
    "use_wandb=false \\\n",
    "debug=false\n",
    "\n",
    "# mga_pl dataset means:\n",
    "# pseudo-labeling images from https://commons.wikimedia.org/w/index.php?search=line+plots&title=Special:MediaSearch&go=Go&type=image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f795bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76ceb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a3bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
